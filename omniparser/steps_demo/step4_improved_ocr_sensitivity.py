#!/usr/bin/env python3
"""
ğŸ¯ 4ë‹¨ê³„: OCR ë¯¼ê°ë„ ê°œì„ 
=======================

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” OCR íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì—¬ ì‘ì€ í…ìŠ¤íŠ¸ë“¤ë„ ê°ì§€í•  ìˆ˜ ìˆë„ë¡ ê°œì„ í•©ë‹ˆë‹¤.
- text_threshold: 0.9 â†’ 0.6 (ë¯¼ê°ë„ ì¦ê°€)
- ì¶”ê°€ íŒŒë¼ë¯¸í„°: low_text=0.3, link_threshold=0.4, canvas_size=3000, mag_ratio=1.5
- ì‘ì€ í…ìŠ¤íŠ¸ "1ì¼", "3", "5", "ë™ë°©" ë“± ê°ì§€ ëª©í‘œ
"""

import sys
import os
sys.path.append('..')

import torch
import time
from PIL import Image
import base64
import io
import csv
import easyocr
from util.utils import check_ocr_box, get_yolo_model, get_caption_model_processor, get_som_labeled_img

def run_step4_improved_ocr():
    print("=" * 60)
    print("ğŸ¯ 4ë‹¨ê³„: OCR ë¯¼ê°ë„ ê°œì„ ")
    print("=" * 60)
    print("âœ… ì´ ë‹¨ê³„ì—ì„œëŠ” OCR íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì—¬ ì‘ì€ í…ìŠ¤íŠ¸ë“¤ë„ ê°ì§€í•©ë‹ˆë‹¤.")
    print("ğŸ“ ì„ê³„ê°’ ë‚®ì¶”ê¸°: 0.9 â†’ 0.6, ì¶”ê°€ íŒŒë¼ë¯¸í„° ì¡°ì •")
    print("")
    
    # ê¸°ë³¸ ì„¤ì •
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ”§ Device: {device}")
    
    # í† ìŠ¤ ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸
    image_path = '../imgs/toss_page.png'
    if not os.path.exists(image_path):
        print(f"âŒ í† ìŠ¤ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        print("ğŸ’¡ toss_page.png íŒŒì¼ì„ OmniParser/imgs/ í´ë”ì— ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        return False
    
    print(f"ğŸ–¼ï¸ í† ìŠ¤ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘: {image_path}")
    
    try:
        # ëª¨ë¸ ë¡œë”©
        print("ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
        
        # SOM ëª¨ë¸
        som_model = get_yolo_model(model_path='../weights/icon_detect/model.pt')
        print("âœ… SOM ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # ìº¡ì…˜ ëª¨ë¸ (Florence2 - ì—¬ì „íˆ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŒ)
        try:
            caption_model_processor = get_caption_model_processor(
                model_name="florence2", 
                model_name_or_path="../weights/icon_caption_florence", 
                device=device
            )
            print("âœ… Florence2 ìº¡ì…˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            florence2_loaded = True
        except Exception as e:
            print(f"âš ï¸ Florence2 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ ì´ ë¬¸ì œëŠ” 5ë‹¨ê³„ì—ì„œ BLIP2ë¡œ í•´ê²°í•  ì˜ˆì •ì…ë‹ˆë‹¤.")
            caption_model_processor = None
            florence2_loaded = False
        
        # OCR ì²˜ë¦¬ (ê°œì„ ëœ ë¯¼ê°ë„ ì„¤ì •)
        print("\nğŸ” OCR ì²˜ë¦¬ ì¤‘...")
        print("ğŸ¯ ê°œì„ ëœ ì„¤ì •: ë‚®ì€ ì„ê³„ê°’ 0.6 + ì¶”ê°€ íŒŒë¼ë¯¸í„° ì¡°ì •")
        print("   - text_threshold: 0.9 â†’ 0.6")
        print("   - low_text: 0.3 (ì¶”ê°€)")
        print("   - link_threshold: 0.4 (ì¶”ê°€)")
        print("   - canvas_size: 3000 (ì¶”ê°€)")
        print("   - mag_ratio: 1.5 (ì¶”ê°€)")
        
        start_time = time.time()
        
        # ê°œì„ ëœ íŒŒë¼ë¯¸í„°ë¡œ EasyOCR ì´ˆê¸°í™”
        reader = easyocr.Reader(['ko', 'en'], gpu=torch.cuda.is_available())
        
        # ì´ë¯¸ì§€ ì½ê¸°
        image = Image.open(image_path)
        
        # ê°œì„ ëœ íŒŒë¼ë¯¸í„°ë¡œ EasyOCR ì‹¤í–‰
        results = reader.readtext(
            image_path,
            paragraph=False,
            text_threshold=0.6,      # ë‚®ì•„ì§„ ì„ê³„ê°’ (0.9 â†’ 0.6)
            low_text=0.3,            # ë‚®ì€ ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ ê°ì§€
            link_threshold=0.4,      # í…ìŠ¤íŠ¸ ì—°ê²° ì„ê³„ê°’
            width_ths=0.7,
            height_ths=0.7,
            # ì¶”ê°€ ì„±ëŠ¥ íŒŒë¼ë¯¸í„°
            canvas_size=3000,        # ìº”ë²„ìŠ¤ í¬ê¸° ì¦ê°€
            mag_ratio=1.5            # í™•ëŒ€ ë¹„ìœ¨
        )
        
        # ê²°ê³¼ë¥¼ check_ocr_box í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        text = []
        ocr_bbox = []
        
        for (bbox, txt, conf) in results:
            if conf >= 0.6:  # ë‚®ì•„ì§„ ì„ê³„ê°’ ì ìš©
                text.append(txt)
                # bboxë¥¼ xyxy í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                x_coords = [point[0] for point in bbox]
                y_coords = [point[1] for point in bbox]
                x1, y1 = min(x_coords), min(y_coords)
                x2, y2 = max(x_coords), max(y_coords)
                ocr_bbox.append([x1, y1, x2, y2])
        
        ocr_time = time.time() - start_time
        print(f"â±ï¸ OCR ì™„ë£Œ: {ocr_time:.2f}ì´ˆ, {len(text)}ê°œ í…ìŠ¤íŠ¸ ê°ì§€")
        
        # ê°ì§€ëœ í…ìŠ¤íŠ¸ ë¶„ì„
        print("\nğŸ“ ê°ì§€ëœ í…ìŠ¤íŠ¸ ë¶„ì„:")
        korean_count = 0
        english_count = 0
        korean_texts = []
        small_texts = []  # ì‘ì€ í…ìŠ¤íŠ¸ë“¤ (ê¸¸ì´ 3ì ì´í•˜)
        
        for i, txt in enumerate(text):
            # í•œêµ­ì–´ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            has_korean = any('\uac00' <= char <= '\ud7af' for char in txt)
            if has_korean:
                korean_count += 1
                korean_texts.append(txt)
            else:
                english_count += 1
            
            # ì‘ì€ í…ìŠ¤íŠ¸ í™•ì¸ (3ì ì´í•˜)
            if len(txt.strip()) <= 3:
                small_texts.append(txt)
            
            if i < 20:  # ì²˜ìŒ 20ê°œ ì¶œë ¥
                size_indicator = " (ì‘ì€ í…ìŠ¤íŠ¸)" if len(txt.strip()) <= 3 else ""
                print(f"  {i}: {txt} {'(í•œêµ­ì–´ í¬í•¨)' if has_korean else '(ì˜ì–´/ìˆ«ì)'}{size_indicator}")
        
        if len(text) > 20:
            print(f"  ... ì´ {len(text)}ê°œ")
        
        print(f"\nğŸ“Š ì–¸ì–´ë³„ ë¶„ì„: í•œêµ­ì–´ {korean_count}ê°œ, ì˜ì–´/ìˆ«ì {english_count}ê°œ")
        print(f"ğŸ” ì‘ì€ í…ìŠ¤íŠ¸: {len(small_texts)}ê°œ (3ì ì´í•˜)")
        
        # ì‘ì€ í…ìŠ¤íŠ¸ë“¤ ì¶œë ¥
        if small_texts:
            print("ğŸ¯ ê°ì§€ëœ ì‘ì€ í…ìŠ¤íŠ¸ë“¤:")
            for txt in small_texts[:15]:
                print(f"    '{txt}'")
            if len(small_texts) > 15:
                print(f"    ... ì´ {len(small_texts)}ê°œ")
        
        # 3ë‹¨ê³„ ëŒ€ë¹„ ê°œì„  í™•ì¸
        print(f"\nâœ… ê°œì„  íš¨ê³¼: 3ë‹¨ê³„ ~91ê°œ â†’ 4ë‹¨ê³„ {len(text)}ê°œ (+{len(text)-91}ê°œ)")
        
        # SOM + ìº¡ì…˜ ì²˜ë¦¬ (ì—¬ì „íˆ Florence2 ë¬¸ì œ ìˆì„ ìˆ˜ ìˆìŒ)
        if florence2_loaded and caption_model_processor:
            print("\nğŸ·ï¸ UI ìš”ì†Œ ê°ì§€ ë° ìº¡ì…˜ ìƒì„± ì‹œë„ ì¤‘...")
            try:
                start_time = time.time()
                
                dino_labeled_img, label_coordinates, parsed_content_list = get_som_labeled_img(
                    image,
                    som_model,
                    BOX_TRESHOLD=0.05,
                    output_coord_in_ratio=True,
                    ocr_bbox=ocr_bbox,
                    caption_model_processor=caption_model_processor,
                    ocr_text=text,
                    use_local_semantics=True,
                    iou_threshold=0.7,
                    scale_img=False,
                    batch_size=128
                )
                
                som_time = time.time() - start_time
                print(f"â±ï¸ UI ìš”ì†Œ ê°ì§€ ì™„ë£Œ: {som_time:.2f}ì´ˆ")
                
            except Exception as e:
                print(f"âŒ Florence2 ìº¡ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
                print("ğŸ’¡ í•´ê²° ë°©ë²•: 5ë‹¨ê³„ì—ì„œ BLIP2 ëª¨ë¸ë¡œ êµì²´ ì˜ˆì •")
                dino_labeled_img = None
                parsed_content_list = []
        else:
            print("\nâš ï¸ ìº¡ì…˜ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ UI ìš”ì†Œ ê°ì§€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            dino_labeled_img = None
            parsed_content_list = []
        
        # ê²°ê³¼ ì €ì¥
        output_dir = "step4_results"
        os.makedirs(output_dir, exist_ok=True)
        
        # ë¼ë²¨ëœ ì´ë¯¸ì§€ ì €ì¥ (ê°€ëŠ¥í•œ ê²½ìš°)
        if dino_labeled_img:
            labeled_image = Image.open(io.BytesIO(base64.b64decode(dino_labeled_img)))
            labeled_image.save(f"{output_dir}/toss_labeled.png")
            print(f"ğŸ’¾ ë¼ë²¨ëœ ì´ë¯¸ì§€ ì €ì¥: {output_dir}/toss_labeled.png")
        else:
            print("âš ï¸ ë¼ë²¨ëœ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨ (Florence2 ë¬¸ì œ)")
        
        # OCR ê²°ê³¼ ì €ì¥
        with open(f"{output_dir}/toss_ocr.txt", 'w', encoding='utf-8') as f:
            f.write("# 4ë‹¨ê³„ OCR ê²°ê³¼ - ë¯¼ê°ë„ ê°œì„ \n")
            f.write(f"# ì´ {len(text)}ê°œ í…ìŠ¤íŠ¸, í•œêµ­ì–´ {korean_count}ê°œ, ì˜ì–´/ìˆ«ì {english_count}ê°œ\n")
            f.write(f"# ì‘ì€ í…ìŠ¤íŠ¸ {len(small_texts)}ê°œ (3ì ì´í•˜)\n\n")
            
            f.write("## ê°œì„ ëœ OCR íŒŒë¼ë¯¸í„°:\n")
            f.write("- text_threshold: 0.9 â†’ 0.6\n")
            f.write("- low_text: 0.3\n")
            f.write("- link_threshold: 0.4\n")
            f.write("- canvas_size: 3000\n")
            f.write("- mag_ratio: 1.5\n\n")
            
            f.write("## ì‘ì€ í…ìŠ¤íŠ¸ ëª©ë¡:\n")
            for txt in small_texts:
                f.write(f"ì‘ì€í…ìŠ¤íŠ¸: '{txt}'\n")
            
            f.write("\n## í•œêµ­ì–´ í…ìŠ¤íŠ¸ ëª©ë¡:\n")
            for txt in korean_texts:
                f.write(f"í•œêµ­ì–´: {txt}\n")
            
            f.write("\n## ì „ì²´ í…ìŠ¤íŠ¸ ëª©ë¡:\n")
            for i, txt in enumerate(text):
                has_korean = any('\uac00' <= char <= '\ud7af' for char in txt)
                size_info = " (ì‘ì€í…ìŠ¤íŠ¸)" if len(txt.strip()) <= 3 else ""
                f.write(f"{i}: {txt} {'(í•œêµ­ì–´)' if has_korean else '(ì˜ì–´/ìˆ«ì)'}{size_info}\n")
        
        # ìš”ì†Œ ê²°ê³¼ ì €ì¥
        if parsed_content_list:
            with open(f"{output_dir}/toss_elements.csv", 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=parsed_content_list[0].keys())
                writer.writeheader()
                writer.writerows(parsed_content_list)
        
        # 3ë‹¨ê³„ ëŒ€ë¹„ ê°œì„ ì  ë¶„ì„
        print("\n" + "=" * 60)
        print("ğŸ¯ 4ë‹¨ê³„ OCR ë¯¼ê°ë„ ê°œì„  ê²°ê³¼:")
        print("=" * 60)
        print(f"ğŸ” OCR í…ìŠ¤íŠ¸: {len(text)}ê°œ (í•œêµ­ì–´ {korean_count}ê°œ, ì˜ì–´/ìˆ«ì {english_count}ê°œ)")
        print(f"ğŸ¯ ì‘ì€ í…ìŠ¤íŠ¸: {len(small_texts)}ê°œ (3ì ì´í•˜)")
        print(f"ğŸ·ï¸ UI ìš”ì†Œ: {len(parsed_content_list)}ê°œ")
        print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: OCR {ocr_time:.2f}ì´ˆ")
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_dir}/")
        
        print("\nâœ… 4ë‹¨ê³„ ì£¼ìš” ê°œì„ ì‚¬í•­:")
        print(f"  1. âœ… OCR ë¯¼ê°ë„ í–¥ìƒ: ì„ê³„ê°’ 0.9 â†’ 0.6")
        print(f"  2. âœ… ì‘ì€ í…ìŠ¤íŠ¸ ê°ì§€: {len(small_texts)}ê°œ ì¶”ê°€")
        print(f"  3. âœ… ì „ì²´ í…ìŠ¤íŠ¸ ì¦ê°€: 3ë‹¨ê³„ ~91ê°œ â†’ 4ë‹¨ê³„ {len(text)}ê°œ")
        
        # íŠ¹ë³„íˆ ì°¾ê³  ìˆë˜ ì‘ì€ í…ìŠ¤íŠ¸ë“¤ í™•ì¸
        target_small_texts = ['1ì¼', '3', '4', '5', '6', 'ë™ë°©', '7', 'í† ìŠ¤']
        found_targets = [txt for txt in text if any(target in txt for target in target_small_texts)]
        if found_targets:
            print(f"  4. âœ… ëª©í‘œ ì‘ì€ í…ìŠ¤íŠ¸ ê°ì§€: {found_targets}")
        
        remaining_issues = []
        if len(parsed_content_list) == 0:
            remaining_issues.append("UI ìš”ì†Œ ê°ì§€ ì‹¤íŒ¨ (Florence2 ë¬¸ì œ)")
        
        if remaining_issues:
            print("\nâš ï¸ ì•„ì§ ë‚¨ì€ ë¬¸ì œ:")
            for i, issue in enumerate(remaining_issues, 1):
                print(f"  {i}. {issue}")
        
        print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„ ê³„íš:")
        print("  5ë‹¨ê³„: BLIP2 ëª¨ë¸ë¡œ UI ìš”ì†Œ ê°ì§€ ë¬¸ì œ í•´ê²°")
        print("  6ë‹¨ê³„: ìµœì¢… í†µí•© ì†”ë£¨ì…˜")
        
        return True
        
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = run_step4_improved_ocr()
    
    if success:
        print("\n" + "ğŸ¯" * 20)
        print("4ë‹¨ê³„ OCR ë¯¼ê°ë„ ê°œì„  ì™„ë£Œ! ë‹¤ìŒì€ 5ë‹¨ê³„ë¡œ ì§„í–‰í•´ë³´ì„¸ìš”.")
        print("python step5_blip2_model_switch.py")
        print("ğŸ¯" * 20)
    else:
        print("\nâŒ 4ë‹¨ê³„ ì‹¤í–‰ ì‹¤íŒ¨. ëª¨ë¸ íŒŒì¼ê³¼ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.") 