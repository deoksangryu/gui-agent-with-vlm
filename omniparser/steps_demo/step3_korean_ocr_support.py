#!/usr/bin/env python3
"""
ğŸ‡°ğŸ‡· 3ë‹¨ê³„: í•œêµ­ì–´ OCR ì§€ì› ì¶”ê°€
==============================

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” EasyOCR ì–¸ì–´ ì„¤ì •ì„ ìˆ˜ì •í•˜ì—¬ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê°ì§€ë¥¼ í™œì„±í™”í•©ë‹ˆë‹¤.
- EasyOCR ì–¸ì–´: ['en'] â†’ ['ko', 'en']
- í•œêµ­ì–´ í…ìŠ¤íŠ¸ "í† ìŠ¤ì¦ê¶Œ", "ì£¼ì‹", "ì½”ìŠ¤í”¼" ë“± ê°ì§€ ê°€ëŠ¥
- OCR í…ìŠ¤íŠ¸ ìˆ˜ í¬ê²Œ ì¦ê°€ ì˜ˆìƒ (~30ê°œ â†’ ~91ê°œ)
"""

import sys
import os
sys.path.append('..')

import torch
import time
from PIL import Image
import base64
import io
import csv
import easyocr
from util.utils import check_ocr_box, get_yolo_model, get_caption_model_processor, get_som_labeled_img

def run_step3_korean_ocr():
    print("=" * 60)
    print("ğŸ‡°ğŸ‡· 3ë‹¨ê³„: í•œêµ­ì–´ OCR ì§€ì› ì¶”ê°€")
    print("=" * 60)
    print("âœ… ì´ ë‹¨ê³„ì—ì„œëŠ” EasyOCR ì–¸ì–´ ì„¤ì •ì„ ìˆ˜ì •í•˜ì—¬ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.")
    print("ğŸ“ ì–¸ì–´ ì„¤ì •: ['en'] â†’ ['ko', 'en']")
    print("")
    
    # ê¸°ë³¸ ì„¤ì •
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ”§ Device: {device}")
    
    # í† ìŠ¤ ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸
    image_path = '../imgs/toss_page.png'
    if not os.path.exists(image_path):
        print(f"âŒ í† ìŠ¤ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        print("ğŸ’¡ toss_page.png íŒŒì¼ì„ OmniParser/imgs/ í´ë”ì— ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        return False
    
    print(f"ğŸ–¼ï¸ í† ìŠ¤ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘: {image_path}")
    
    try:
        # ëª¨ë¸ ë¡œë”©
        print("ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
        
        # SOM ëª¨ë¸
        som_model = get_yolo_model(model_path='../weights/icon_detect/model.pt')
        print("âœ… SOM ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # ìº¡ì…˜ ëª¨ë¸ (Florence2 - ì—¬ì „íˆ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŒ)
        try:
            caption_model_processor = get_caption_model_processor(
                model_name="florence2", 
                model_name_or_path="../weights/icon_caption_florence", 
                device=device
            )
            print("âœ… Florence2 ìº¡ì…˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            florence2_loaded = True
        except Exception as e:
            print(f"âš ï¸ Florence2 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ ì´ ë¬¸ì œëŠ” 5ë‹¨ê³„ì—ì„œ BLIP2ë¡œ í•´ê²°í•  ì˜ˆì •ì…ë‹ˆë‹¤.")
            caption_model_processor = None
            florence2_loaded = False
        
        # OCR ì²˜ë¦¬ (í•œêµ­ì–´ ì§€ì› ì¶”ê°€)
        print("\nğŸ” OCR ì²˜ë¦¬ ì¤‘...")
        print("ğŸ‡°ğŸ‡· ìƒˆë¡œìš´ ì„¤ì •: í•œêµ­ì–´+ì˜ì–´ OCR ì§€ì›, ì„ê³„ê°’ 0.9 ìœ ì§€")
        start_time = time.time()
        
        # í•œêµ­ì–´ ì§€ì›ì„ ìœ„í•œ EasyOCR ì´ˆê¸°í™”
        reader = easyocr.Reader(['ko', 'en'], gpu=torch.cuda.is_available())
        
        # ì´ë¯¸ì§€ ì½ê¸°
        image = Image.open(image_path)
        
        # EasyOCRë¡œ í…ìŠ¤íŠ¸ ê°ì§€
        results = reader.readtext(
            image_path,
            paragraph=False,
            text_threshold=0.9,  # ì•„ì§ ë†’ì€ ì„ê³„ê°’ ìœ ì§€
            width_ths=0.7,
            height_ths=0.7
        )
        
        # ê²°ê³¼ë¥¼ check_ocr_box í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        text = []
        ocr_bbox = []
        
        for (bbox, txt, conf) in results:
            if conf >= 0.9:  # ì„ê³„ê°’ í™•ì¸
                text.append(txt)
                # bboxë¥¼ xyxy í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                x_coords = [point[0] for point in bbox]
                y_coords = [point[1] for point in bbox]
                x1, y1 = min(x_coords), min(y_coords)
                x2, y2 = max(x_coords), max(y_coords)
                ocr_bbox.append([x1, y1, x2, y2])
        
        ocr_time = time.time() - start_time
        print(f"â±ï¸ OCR ì™„ë£Œ: {ocr_time:.2f}ì´ˆ, {len(text)}ê°œ í…ìŠ¤íŠ¸ ê°ì§€")
        
        # ê°ì§€ëœ í…ìŠ¤íŠ¸ ë¶„ì„
        print("\nğŸ“ ê°ì§€ëœ í…ìŠ¤íŠ¸ ë¶„ì„:")
        korean_count = 0
        english_count = 0
        korean_texts = []
        
        for i, txt in enumerate(text):
            # í•œêµ­ì–´ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            has_korean = any('\uac00' <= char <= '\ud7af' for char in txt)
            if has_korean:
                korean_count += 1
                korean_texts.append(txt)
            else:
                english_count += 1
            
            if i < 15:  # ì²˜ìŒ 15ê°œ ì¶œë ¥
                print(f"  {i}: {txt} {'(í•œêµ­ì–´ í¬í•¨)' if has_korean else '(ì˜ì–´/ìˆ«ì)'}")
        
        if len(text) > 15:
            print(f"  ... ì´ {len(text)}ê°œ")
        
        print(f"\nğŸ“Š ì–¸ì–´ë³„ ë¶„ì„: í•œêµ­ì–´ {korean_count}ê°œ, ì˜ì–´/ìˆ«ì {english_count}ê°œ")
        
        # í•œêµ­ì–´ í…ìŠ¤íŠ¸ í–¥ìƒë„ í™•ì¸
        if korean_count > 0:
            print("âœ… ì„±ê³µ: í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê°ì§€ë¨!")
            print("ğŸ‡°ğŸ‡· ì£¼ìš” í•œêµ­ì–´ í…ìŠ¤íŠ¸:")
            for i, txt in enumerate(korean_texts[:10]):
                print(f"    {txt}")
            if len(korean_texts) > 10:
                print(f"    ... ì´ {len(korean_texts)}ê°œ")
        
        # SOM + ìº¡ì…˜ ì²˜ë¦¬ (ì—¬ì „íˆ Florence2 ë¬¸ì œ ìˆì„ ìˆ˜ ìˆìŒ)
        if florence2_loaded and caption_model_processor:
            print("\nğŸ·ï¸ UI ìš”ì†Œ ê°ì§€ ë° ìº¡ì…˜ ìƒì„± ì‹œë„ ì¤‘...")
            try:
                start_time = time.time()
                
                dino_labeled_img, label_coordinates, parsed_content_list = get_som_labeled_img(
                    image,
                    som_model,
                    BOX_TRESHOLD=0.05,
                    output_coord_in_ratio=True,
                    ocr_bbox=ocr_bbox,
                    caption_model_processor=caption_model_processor,
                    ocr_text=text,
                    use_local_semantics=True,
                    iou_threshold=0.7,
                    scale_img=False,
                    batch_size=128
                )
                
                som_time = time.time() - start_time
                print(f"â±ï¸ UI ìš”ì†Œ ê°ì§€ ì™„ë£Œ: {som_time:.2f}ì´ˆ")
                
            except Exception as e:
                print(f"âŒ Florence2 ìº¡ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
                print("ğŸ’¡ í•´ê²° ë°©ë²•: 5ë‹¨ê³„ì—ì„œ BLIP2 ëª¨ë¸ë¡œ êµì²´ ì˜ˆì •")
                dino_labeled_img = None
                parsed_content_list = []
        else:
            print("\nâš ï¸ ìº¡ì…˜ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ UI ìš”ì†Œ ê°ì§€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            dino_labeled_img = None
            parsed_content_list = []
        
        # ê²°ê³¼ ì €ì¥
        output_dir = "step3_results"
        os.makedirs(output_dir, exist_ok=True)
        
        # ë¼ë²¨ëœ ì´ë¯¸ì§€ ì €ì¥ (ê°€ëŠ¥í•œ ê²½ìš°)
        if dino_labeled_img:
            labeled_image = Image.open(io.BytesIO(base64.b64decode(dino_labeled_img)))
            labeled_image.save(f"{output_dir}/toss_labeled.png")
            print(f"ğŸ’¾ ë¼ë²¨ëœ ì´ë¯¸ì§€ ì €ì¥: {output_dir}/toss_labeled.png")
        else:
            print("âš ï¸ ë¼ë²¨ëœ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨ (Florence2 ë¬¸ì œ)")
        
        # OCR ê²°ê³¼ ì €ì¥
        with open(f"{output_dir}/toss_ocr.txt", 'w', encoding='utf-8') as f:
            f.write("# 3ë‹¨ê³„ OCR ê²°ê³¼ - í•œêµ­ì–´ ì§€ì› ì¶”ê°€\n")
            f.write(f"# ì´ {len(text)}ê°œ í…ìŠ¤íŠ¸, í•œêµ­ì–´ {korean_count}ê°œ, ì˜ì–´/ìˆ«ì {english_count}ê°œ\n\n")
            f.write("## í•œêµ­ì–´ í…ìŠ¤íŠ¸ ëª©ë¡:\n")
            for txt in korean_texts:
                f.write(f"í•œêµ­ì–´: {txt}\n")
            f.write("\n## ì „ì²´ í…ìŠ¤íŠ¸ ëª©ë¡:\n")
            for i, txt in enumerate(text):
                has_korean = any('\uac00' <= char <= '\ud7af' for char in txt)
                f.write(f"{i}: {txt} {'(í•œêµ­ì–´)' if has_korean else '(ì˜ì–´/ìˆ«ì)'}\n")
        
        # ìš”ì†Œ ê²°ê³¼ ì €ì¥
        if parsed_content_list:
            with open(f"{output_dir}/toss_elements.csv", 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=parsed_content_list[0].keys())
                writer.writeheader()
                writer.writerows(parsed_content_list)
        
        # 2ë‹¨ê³„ ëŒ€ë¹„ ê°œì„ ì  ë¶„ì„
        print("\n" + "=" * 60)
        print("ğŸ‡°ğŸ‡· 3ë‹¨ê³„ í•œêµ­ì–´ OCR ê²°ê³¼:")
        print("=" * 60)
        print(f"ğŸ” OCR í…ìŠ¤íŠ¸: {len(text)}ê°œ (í•œêµ­ì–´ {korean_count}ê°œ, ì˜ì–´/ìˆ«ì {english_count}ê°œ)")
        print(f"ğŸ·ï¸ UI ìš”ì†Œ: {len(parsed_content_list)}ê°œ")
        print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: OCR {ocr_time:.2f}ì´ˆ")
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_dir}/")
        
        print("\nâœ… 3ë‹¨ê³„ ì£¼ìš” ê°œì„ ì‚¬í•­:")
        if korean_count > 0:
            print(f"  1. âœ… í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê°ì§€ ì„±ê³µ: {korean_count}ê°œ")
            print(f"     ì£¼ìš” í…ìŠ¤íŠ¸: {', '.join(korean_texts[:5])}")
        print(f"  2. âœ… ì „ì²´ í…ìŠ¤íŠ¸ ì¦ê°€: ~30ê°œ â†’ {len(text)}ê°œ")
        
        remaining_issues = []
        if len(parsed_content_list) == 0:
            remaining_issues.append("UI ìš”ì†Œ ê°ì§€ ì‹¤íŒ¨ (Florence2 ë¬¸ì œ)")
        if korean_count < 20:
            remaining_issues.append("ì‘ì€ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì¼ë¶€ ëˆ„ë½ (ë†’ì€ ì„ê³„ê°’)")
        
        if remaining_issues:
            print("\nâš ï¸ ì•„ì§ ë‚¨ì€ ë¬¸ì œ:")
            for i, issue in enumerate(remaining_issues, 1):
                print(f"  {i}. {issue}")
        
        print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„ ê³„íš:")
        print("  4ë‹¨ê³„: OCR ë¯¼ê°ë„ ê°œì„  (ì„ê³„ê°’ ë‚®ì¶”ê¸°)")
        print("  5ë‹¨ê³„: BLIP2 ëª¨ë¸ë¡œ UI ìš”ì†Œ ê°ì§€ ë¬¸ì œ í•´ê²°")
        
        return True
        
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = run_step3_korean_ocr()
    
    if success:
        print("\n" + "ğŸ‡°ğŸ‡·" * 20)
        print("3ë‹¨ê³„ í•œêµ­ì–´ OCR ì§€ì› ì™„ë£Œ! ë‹¤ìŒì€ 4ë‹¨ê³„ë¡œ ì§„í–‰í•´ë³´ì„¸ìš”.")
        print("python step4_improved_ocr_sensitivity.py")
        print("ğŸ‡°ğŸ‡·" * 20)
    else:
        print("\nâŒ 3ë‹¨ê³„ ì‹¤í–‰ ì‹¤íŒ¨. ëª¨ë¸ íŒŒì¼ê³¼ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.") 