"""
ê°„ë‹¨í•œ ShowUI í—¬í¼ í…ŒìŠ¤íŠ¸ ë²„ì „

ë°˜ë³µ ìƒì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ìµœì†Œí™”ëœ ë²„ì „ì…ë‹ˆë‹¤.
"""

import os
import torch
import time
from PIL import Image
from qwen_vl_utils import process_vision_info
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor

# GPU ìµœì í™” ì„¤ì •
torch.backends.cuda.enable_mem_efficient_sdp(False)
torch.backends.cuda.enable_flash_sdp(False)

class SimpleShowUIHelper:
    """
    ê°„ë‹¨í•œ ShowUI í—¬í¼
    """
    
    def __init__(self, model_name="Qwen/Qwen2-VL-2B-Instruct", device="auto"):
        print("ğŸ¯ ê°„ë‹¨í•œ ShowUI í—¬í¼ ì´ˆê¸°í™” ì¤‘...")
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬ ì„¤ì •
        self.min_pixels = 256 * 28 * 28
        self.max_pixels = 1344 * 28 * 28
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if device == "auto":
            if torch.cuda.is_available():
                self.device = "cuda"
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                self.device = "mps"
            else:
                self.device = "cpu"
        else:
            self.device = device
        
        print(f"ğŸ“± ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")
        
        try:
            # í”„ë¡œì„¸ì„œ ë° ëª¨ë¸ ë¡œë“œ
            self.processor = AutoProcessor.from_pretrained(
                model_name,
                min_pixels=self.min_pixels,
                max_pixels=self.max_pixels
            )
            
            if self.device == "cpu":
                self.model = Qwen2VLForConditionalGeneration.from_pretrained(
                    model_name,
                    torch_dtype=torch.float32,
                    device_map="cpu"
                )
            else:
                self.model = Qwen2VLForConditionalGeneration.from_pretrained(
                    model_name,
                    torch_dtype=torch.bfloat16,
                    device_map=self.device
                )
            
            print("âœ… ê°„ë‹¨í•œ ShowUI í—¬í¼ ì¤€ë¹„ ì™„ë£Œ!")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            raise
    
    def analyze_ui_simple(self, image_path, context=""):
        """
        ê°„ë‹¨í•œ UI ë¶„ì„
        """
        
        # ë§¤ìš° ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸
        prompt = f"""
ì´ ìŠ¤í¬ë¦°ìƒ·ì—ì„œ í´ë¦­í•  ìˆ˜ ìˆëŠ” ë²„íŠ¼ê³¼ ì…ë ¥í•  ìˆ˜ ìˆëŠ” í•„ë“œë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

ê° ìš”ì†Œì— ëŒ€í•´ ê°„ë‹¨íˆ:
1. ìœ í˜• (ë²„íŠ¼/ì…ë ¥í•„ë“œ/ë§í¬)
2. ìœ„ì¹˜ (ìƒë‹¨/ì¤‘ì•™/í•˜ë‹¨, ì¢Œì¸¡/ì¤‘ì•™/ìš°ì¸¡)
3. í…ìŠ¤íŠ¸ ë‚´ìš©

ì›¹ì•± ì •ë³´: {context}

ê°„ê²°í•˜ê²Œ 5ê°œ ì´í•˜ì˜ ì£¼ìš” ìš”ì†Œë§Œ ë‚˜ì—´í•´ì£¼ì„¸ìš”.
"""
        
        try:
            start_time = time.time()
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            if isinstance(image_path, str):
                image = Image.open(image_path)
            else:
                image = image_path
            
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image",
                            "image": image_path if isinstance(image_path, str) else image,
                            "min_pixels": self.min_pixels,
                            "max_pixels": self.max_pixels,
                        },
                    ],
                }
            ]
            
            # í…œí”Œë¦¿ ì ìš© ë° ì²˜ë¦¬
            text = self.processor.apply_chat_template(
                messages, tokenize=False, add_generation_prompt=True
            )
            
            image_inputs, video_inputs = process_vision_info(messages)
            
            inputs = self.processor(
                text=[text],
                images=image_inputs,
                videos=video_inputs,
                padding=True,
                return_tensors="pt",
            )
            
            inputs = inputs.to(self.device)
            
            # ì‘ë‹µ ìƒì„± (ë§¤ìš° ë³´ìˆ˜ì ì¸ ì„¤ì •)
            print("ğŸ”„ ê°„ë‹¨ ë¶„ì„ ì¤‘...")
            generated_ids = self.model.generate(
                **inputs, 
                max_new_tokens=500,  # ë§¤ìš° ì§§ê²Œ
                do_sample=False,  # ê²°ì •ì  ìƒì„±
                repetition_penalty=1.3,  # ë°˜ë³µ ë°©ì§€ ê°•í™”
                pad_token_id=self.processor.tokenizer.eos_token_id,
                eos_token_id=self.processor.tokenizer.eos_token_id
            )
            
            # ê²°ê³¼ ë””ì½”ë”©
            generated_ids_trimmed = [
                out_ids[len(in_ids):] 
                for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            
            output_text = self.processor.batch_decode(
                generated_ids_trimmed, 
                skip_special_tokens=True, 
                clean_up_tokenization_spaces=False
            )[0]
            
            end_time = time.time()
            print(f"â±ï¸ ë¶„ì„ ì™„ë£Œ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
            
            # ì‘ë‹µ ê¸¸ì´ ì œí•œ (ì•ˆì „ì¥ì¹˜)
            if len(output_text) > 1000:
                output_text = output_text[:1000] + "..."
            
            return output_text.strip()
            
        except Exception as e:
            return f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def test_simple_helper():
    """
    ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    """
    print("ğŸš€ ê°„ë‹¨í•œ ShowUI í—¬í¼ í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    try:
        helper = SimpleShowUIHelper()
    except Exception as e:
        print(f"âŒ í—¬í¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í™•ì¸
    test_images = ["test_screenshot.png", "screenshot.png", "toss_screenshot.png"]
    test_image = None
    
    for img in test_images:
        if os.path.exists(img):
            test_image = img
            break
    
    if not test_image:
        print("âš ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ íŒŒì¼ì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”:")
        for img in test_images:
            print(f"   - {img}")
        return
    
    print(f"ğŸ“¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {test_image}")
    
    # ê°„ë‹¨í•œ ë¶„ì„ ì‹¤í–‰
    context = "í† ìŠ¤ì¦ê¶Œ ë©”ì¸ í™”ë©´ì…ë‹ˆë‹¤."
    print(f"ğŸ’¬ ì»¨í…ìŠ¤íŠ¸: {context}")
    print("\nğŸ”„ ê°„ë‹¨ UI ë¶„ì„ ì‹¤í–‰ ì¤‘...")
    
    try:
        result = helper.analyze_ui_simple(test_image, context)
        print(f"\nğŸ“ ë¶„ì„ ê²°ê³¼:")
        print("="*50)
        print(result)
        print("="*50)
        print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    test_simple_helper() 