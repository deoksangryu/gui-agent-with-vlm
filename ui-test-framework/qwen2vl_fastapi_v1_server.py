"""
Qwen2VL FastAPI v1 ì„œë²„

qwen2vl_webapp_analyzer.pyì˜ ê¸°ëŠ¥ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë©´ì„œ
í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° base64 ì´ë¯¸ì§€ë¥¼ ë°›ì•„ ì²˜ë¦¬í•˜ëŠ” FastAPI ì„œë²„ì…ë‹ˆë‹¤.
"""

import base64
import io
import os
import torch
import time
import subprocess
import tempfile
from typing import Optional
from PIL import Image
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from qwen_vl_utils import process_vision_info
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
import requests
from io import BytesIO

# í™”ë©´ ìŠ¤í¬ë¦°ìƒ·ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import pyautogui
    PYAUTOGUI_AVAILABLE = True
    pyautogui.FAILSAFE = True
    pyautogui.PAUSE = 0.1
    print("âœ… pyautogui ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    PYAUTOGUI_AVAILABLE = False
    print("âš ï¸ pyautoguiê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. ìŠ¤í¬ë¦°ìƒ· ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install pyautogui' ì‹¤í–‰")

# GPU ìµœì í™” ì„¤ì •
torch.backends.cuda.enable_mem_efficient_sdp(False)
torch.backends.cuda.enable_flash_sdp(False)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Qwen2VL WebApp Analyzer API v1",
    description="ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¶„ì„ê¸°ì˜ ì •í™•í•œ ë³µì œë³¸ - Base64 ì´ë¯¸ì§€ ì§€ì›",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ìš”ì²­/ì‘ë‹µ ëª¨ë¸
class ImageAnalysisRequest(BaseModel):
    """ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­ ëª¨ë¸"""
    image_base64: str
    user_context: Optional[str] = ""

class ImageAnalysisResponse(BaseModel):
    """ì´ë¯¸ì§€ ë¶„ì„ ì‘ë‹µ ëª¨ë¸"""
    result: str
    processing_time: float
    success: bool
    error_message: Optional[str] = None

# ì„œë²„ ìŠ¤í¬ë¦°ìƒ· ë¶„ì„ ëª¨ë¸
class ScreenshotAnalysisRequest(BaseModel):
    """ì„œë²„ ìŠ¤í¬ë¦°ìƒ· ë¶„ì„ ìš”ì²­"""
    context: Optional[str] = ""

class ScreenshotAnalysisResponse(BaseModel):
    """ì„œë²„ ìŠ¤í¬ë¦°ìƒ· ë¶„ì„ ì‘ë‹µ"""
    success: bool
    result: str = ""
    error_message: str = ""
    processing_time: float = 0.0

def capture_server_screenshot() -> Image.Image:
    """
    ì„œë²„ì—ì„œ ì „ì²´ í™”ë©´ ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜
    
    Returns:
        PIL Image: ìº¡ì²˜ëœ ìŠ¤í¬ë¦°ìƒ·
    """
    try:
        if PYAUTOGUI_AVAILABLE:
            # pyautoguië¡œ ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜
            screenshot = pyautogui.screenshot()
            print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜ ì™„ë£Œ: {screenshot.size}")
            return screenshot
        else:
            # macOSì˜ ê²½ìš° screencapture ëª…ë ¹ì–´ ì‚¬ìš©
            temp_file = tempfile.NamedTemporaryFile(suffix='.png', delete=False)
            temp_file.close()
            
            subprocess.run(['screencapture', '-x', temp_file.name], check=True)
            screenshot = Image.open(temp_file.name)
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            os.unlink(temp_file.name)
            
            print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜ ì™„ë£Œ: {screenshot.size}")
            return screenshot
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜ ì‹¤íŒ¨: {str(e)}")

class WebAppAnalyzer:
    """
    ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¶„ì„ê¸° - webapp analyzerì™€ ë™ì¼í•œ ê¸°ëŠ¥
    """
    
    def __init__(self, model_name="Qwen/Qwen2-VL-2B-Instruct", device="auto"):
        """
        ì›¹ì•± ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            model_name: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (auto, cpu, cuda, mps ë“±)
        """
        print("ğŸŒ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬ ì„¤ì •
        self.min_pixels = 256 * 28 * 28
        self.max_pixels = 1344 * 28 * 28
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if device == "auto":
            if torch.cuda.is_available():
                self.device = "cuda"
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                self.device = "mps"
            else:
                self.device = "cpu"
        else:
            self.device = device
        
        print(f"ğŸ“± ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")
        
        try:
            # í”„ë¡œì„¸ì„œ ë° ëª¨ë¸ ë¡œë“œ
            self.processor = AutoProcessor.from_pretrained(
                model_name,
                min_pixels=self.min_pixels,
                max_pixels=self.max_pixels
            )
            
            if self.device == "cpu":
                self.model = Qwen2VLForConditionalGeneration.from_pretrained(
                    model_name,
                    torch_dtype=torch.float32,
                    device_map="cpu"
                )
            else:
                self.model = Qwen2VLForConditionalGeneration.from_pretrained(
                    model_name,
                    torch_dtype=torch.bfloat16,
                    device_map=self.device
                )
            
            print("âœ… ì›¹ì•± ë¶„ì„ê¸° ì¤€ë¹„ ì™„ë£Œ!")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            raise
    
    def load_image(self, image_input):
        """ì´ë¯¸ì§€ ë¡œë“œ í•¨ìˆ˜ - webapp analyzerì™€ ë™ì¼"""
        if isinstance(image_input, str):
            if image_input.startswith('http'):
                response = requests.get(image_input)
                image = Image.open(BytesIO(response.content))
            else:
                image = Image.open(image_input)
        else:
            image = image_input
        return image
    
    def analyze_webapp_screenshot(self, image_input, user_context=""):
        """
        ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ìŠ¤í¬ë¦°ìƒ· ë¶„ì„ - webapp analyzerì™€ ë™ì¼í•œ ë¡œì§
        
        Args:
            image_input: ì´ë¯¸ì§€ (PIL Image ê°ì²´ ë˜ëŠ” ê²½ë¡œ)
            user_context: ì‚¬ìš©ì ì œê³µ ë³´ì¶©ì„¤ëª…
            
        Returns:
            str: ë¶„ì„ ê²°ê³¼
        """
        
        # ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ - webapp analyzerì™€ ë™ì¼
        system_prompt = """
ë‹¹ì‹ ì€ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ UI/UX ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. 
ì œê³µëœ ìŠ¤í¬ë¦°ìƒ·ì€ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ í™”ë©´ì…ë‹ˆë‹¤.
í˜„ì¬ í™”ë©´ì— ìˆëŠ” ë‚´ìš©ì„ ì •ë¦¬í•˜ì—¬ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        return self._generate_response(image_input, system_prompt)
    
    def _generate_response(self, image_input, prompt):
        """Qwen2VL ì‘ë‹µ ìƒì„± (ë‚´ë¶€ ë©”ì„œë“œ) - webapp analyzerì™€ ë™ì¼"""
        try:
            start_time = time.time()
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = self.load_image(image_input)
            
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image",
                            "image": image_input if isinstance(image_input, str) else image,
                            "min_pixels": self.min_pixels,
                            "max_pixels": self.max_pixels,
                        },
                    ],
                }
            ]
            
            # í…œí”Œë¦¿ ì ìš© ë° ì²˜ë¦¬
            text = self.processor.apply_chat_template(
                messages, tokenize=False, add_generation_prompt=True
            )
            
            image_inputs, video_inputs = process_vision_info(messages)
            
            inputs = self.processor(
                text=[text],
                images=image_inputs,
                videos=video_inputs,
                padding=True,
                return_tensors="pt",
            )
            
            inputs = inputs.to(self.device)
            
            # ì‘ë‹µ ìƒì„± - íƒ€ì„ì•„ì›ƒ ë°©ì§€ë¥¼ ìœ„í•œ ìµœì í™”ëœ íŒŒë¼ë¯¸í„°
            print("ğŸ”„ ì›¹ì•± ë¶„ì„ ì¤‘...")
            generated_ids = self.model.generate(
                **inputs, 
                max_new_tokens=2000,  # íƒ€ì„ì•„ì›ƒ ë°©ì§€ë¥¼ ìœ„í•´ ê°ì†Œ
                repetition_penalty=1.1,  # ë°˜ë³µ ë°©ì§€
                pad_token_id=self.processor.tokenizer.eos_token_id,
                eos_token_id=self.processor.tokenizer.eos_token_id
            )
            
            # ê²°ê³¼ ë””ì½”ë”©
            generated_ids_trimmed = [
                out_ids[len(in_ids):] 
                for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            
            output_text = self.processor.batch_decode(
                generated_ids_trimmed, 
                skip_special_tokens=True, 
                clean_up_tokenization_spaces=False
            )[0]
            
            end_time = time.time()
            print(f"â±ï¸ ë¶„ì„ ì™„ë£Œ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
            
            return output_text.strip()
            
        except Exception as e:
            return f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ì „ì—­ ë¶„ì„ê¸° ì´ˆê¸°í™”
analyzer = None

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë“œ"""
    global analyzer
    try:
        print("ğŸš€ FastAPI v1 ì„œë²„ ì‹œì‘ - ëª¨ë¸ ë¡œë”© ì¤‘...")
        analyzer = WebAppAnalyzer()
        print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        raise

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "Qwen2VL WebApp Analyzer API v1",
        "description": "webapp analyzerì™€ ë™ì¼í•œ ê¸°ëŠ¥ì˜ FastAPI ì„œë²„",
        "version": "1.0.0",
        "endpoints": {
            "POST /analyze": "ì´ë¯¸ì§€ ë¶„ì„",
            "GET /health": "ì„œë²„ ìƒíƒœ í™•ì¸"
        }
    }

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    global analyzer
    return {
        "status": "healthy" if analyzer is not None else "not_ready",
        "model_loaded": analyzer is not None,
        "device": analyzer.device if analyzer else "unknown"
    }

@app.post("/analyze", response_model=ImageAnalysisResponse)
async def analyze_image(request: ImageAnalysisRequest):
    """
    ì´ë¯¸ì§€ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸ - webapp analyzerì™€ ë™ì¼í•œ ê¸°ëŠ¥
    
    Args:
        request: base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ì™€ ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸
        
    Returns:
        ImageAnalysisResponse: webapp analyzerì™€ ë™ì¼í•œ ë¶„ì„ ê²°ê³¼
    """
    global analyzer
    
    if analyzer is None:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ì•„ì§ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    start_time = time.time()
    
    try:
        # Base64 ì´ë¯¸ì§€ ë””ì½”ë”©
        try:
            # base64 í—¤ë” ì œê±° (data:image/png;base64, ë“±)
            if ',' in request.image_base64:
                base64_data = request.image_base64.split(',')[1]
            else:
                base64_data = request.image_base64
            
            # Base64 ë””ì½”ë”©
            image_data = base64.b64decode(base64_data)
            image = Image.open(io.BytesIO(image_data))
            
            # RGBAë¥¼ RGBë¡œ ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)
            if image.mode == 'RGBA':
                image = image.convert('RGB')
                
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: {str(e)}")
        
        # webapp analyzerì™€ ë™ì¼í•œ ë¶„ì„ ì‹¤í–‰
        try:
            result = analyzer.analyze_webapp_screenshot(image, request.user_context)
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        
        processing_time = time.time() - start_time
        
        return ImageAnalysisResponse(
            result=result,
            processing_time=processing_time,
            success=True
        )
        
    except HTTPException:
        raise
    except Exception as e:
        processing_time = time.time() - start_time
        return ImageAnalysisResponse(
            result="",
            processing_time=processing_time,
            success=False,
            error_message=str(e)
        )

@app.post("/analyze-screenshot", response_model=ScreenshotAnalysisResponse)
async def analyze_screenshot(request: ScreenshotAnalysisRequest):
    """
    ì„œë²„ì—ì„œ ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜ í›„ ë¶„ì„
    
    Args:
        request: ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        
    Returns:
        ScreenshotAnalysisResponse: ìŠ¤í¬ë¦°ìƒ· ë¶„ì„ ê²°ê³¼
    """
    global analyzer
    
    if analyzer is None:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ì•„ì§ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    start_time = time.time()
    
    try:
        print(f"ğŸ“¸ ì„œë²„ ìŠ¤í¬ë¦°ìƒ· ë¶„ì„ ì‹œì‘: '{request.context}'")
        
        # 1. ì„œë²„ì—ì„œ ì „ì²´ í™”ë©´ ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜
        screenshot = capture_server_screenshot()
        
        # 2. Qwen2VLë¡œ ìŠ¤í¬ë¦°ìƒ· ë¶„ì„
        try:
            result = analyzer.analyze_webapp_screenshot(screenshot, request.context)
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        
        processing_time = time.time() - start_time
        print(f"âœ… ì„œë²„ ìŠ¤í¬ë¦°ìƒ· ë¶„ì„ ì™„ë£Œ ({processing_time:.2f}ì´ˆ)")
        
        return ScreenshotAnalysisResponse(
            success=True,
            result=result,
            processing_time=processing_time
        )
        
    except Exception as e:
        error_msg = f"ì„œë²„ ìŠ¤í¬ë¦°ìƒ· ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        print(f"âŒ {error_msg}")
        
        return ScreenshotAnalysisResponse(
            success=False,
            error_message=error_msg,
            processing_time=time.time() - start_time
        )

if __name__ == "__main__":
    import uvicorn
    
    print("ğŸŒ Qwen2VL FastAPI v1 ì„œë²„ ì‹œì‘")
    print("ğŸ“ ì„œë²„ ì£¼ì†Œ: http://localhost:8000")
    print("ğŸ“– API ë¬¸ì„œ: http://localhost:8000/docs")
    print("ğŸ”„ webapp analyzerì™€ ë™ì¼í•œ ê¸°ëŠ¥ ì œê³µ")
    
    uvicorn.run(
        "qwen2vl_fastapi_v1_server:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        log_level="info"
    ) 