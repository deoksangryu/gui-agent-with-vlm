"""
Qwen2VL ê¸°ë°˜ ì´ë¯¸ì§€ ì„¤ëª… í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ê²€ì¦ëœ Qwen2VL-2B-Instruct ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ì„¤ëª…í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
ShowUI ë…¸íŠ¸ë¶ì—ì„œ í™•ì¸ëœ ì‘ë™í•˜ëŠ” ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. ì´ë¯¸ì§€ ì „ì²´ ì„¤ëª… ìƒì„±
2. UI ìš”ì†Œ ì‹ë³„ ë° ì„¤ëª…
3. í…ìŠ¤íŠ¸ ì¸ì‹ ë° ìš”ì•½
4. í™”ë©´ ë ˆì´ì•„ì›ƒ ë¶„ì„
5. ì‚¬ìš©ì ì •ì˜ ì§ˆë¬¸ ì‘ë‹µ
"""

import os
import torch
import time
from PIL import Image
from io import BytesIO
import requests
from qwen_vl_utils import process_vision_info
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor

# GPU ìµœì í™” ì„¤ì • (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´)
torch.backends.cuda.enable_mem_efficient_sdp(False)
torch.backends.cuda.enable_flash_sdp(False)

class Qwen2VLDescriber:
    """
    Qwen2VLì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì„¤ëª… í´ë˜ìŠ¤
    """
    
    def __init__(self, model_name="Qwen/Qwen2-VL-2B-Instruct", device="auto"):
        """
        Qwen2VL ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            model_name: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (auto, cpu, cuda, mps ë“±)
        """
        print(f"ğŸ¤– Qwen2VL ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬ ì„¤ì •
        self.min_pixels = 256 * 28 * 28
        self.max_pixels = 1344 * 28 * 28
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if device == "auto":
            if torch.cuda.is_available():
                self.device = "cuda"
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                self.device = "mps"
            else:
                self.device = "cpu"
        else:
            self.device = device
        
        print(f"ğŸ“± ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")
        
        try:
            # í”„ë¡œì„¸ì„œ ë¡œë“œ
            self.processor = AutoProcessor.from_pretrained(
                model_name,
                min_pixels=self.min_pixels,
                max_pixels=self.max_pixels
            )
            
            # ëª¨ë¸ ë¡œë“œ
            if self.device == "cpu":
                self.model = Qwen2VLForConditionalGeneration.from_pretrained(
                    model_name,
                    torch_dtype=torch.float32,
                    device_map="cpu"
                )
            else:
                self.model = Qwen2VLForConditionalGeneration.from_pretrained(
                    model_name,
                    torch_dtype=torch.bfloat16,
                    device_map=self.device
                )
            
            print("âœ… Qwen2VL ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            raise
    
    def load_image(self, image_input):
        """
        ì´ë¯¸ì§€ ë¡œë“œ (íŒŒì¼ ê²½ë¡œ, URL, PIL Image ì§€ì›)
        
        Args:
            image_input: ì´ë¯¸ì§€ ê²½ë¡œ, URL, ë˜ëŠ” PIL Image ê°ì²´
            
        Returns:
            PIL.Image: ë¡œë“œëœ ì´ë¯¸ì§€
        """
        if isinstance(image_input, str):
            if image_input.startswith('http'):
                # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                response = requests.get(image_input)
                image = Image.open(BytesIO(response.content))
            else:
                # ë¡œì»¬ íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
                image = Image.open(image_input)
        else:
            # ì´ë¯¸ PIL Imageì¸ ê²½ìš°
            image = image_input
        
        return image
    
    def describe_image(self, image_input, custom_prompt=None):
        """
        ì´ë¯¸ì§€ ì „ì²´ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª… ìƒì„±
        
        Args:
            image_input: ì´ë¯¸ì§€ ê²½ë¡œ, URL, ë˜ëŠ” PIL Image
            custom_prompt: ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ (ì„ íƒì‚¬í•­)
            
        Returns:
            str: ì´ë¯¸ì§€ ì„¤ëª… í…ìŠ¤íŠ¸
        """
        # ê¸°ë³¸ ì„¤ëª… í”„ë¡¬í”„íŠ¸
        if custom_prompt is None:
            prompt = """ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. ë‹¤ìŒ ì‚¬í•­ë“¤ì„ í¬í•¨í•´ì£¼ì„¸ìš”:
1. ì „ë°˜ì ì¸ í™”ë©´ êµ¬ì„±ê³¼ ë ˆì´ì•„ì›ƒ
2. ì£¼ìš” UI ìš”ì†Œë“¤ (ë²„íŠ¼, í…ìŠ¤íŠ¸, ì…ë ¥ì°½ ë“±)
3. í…ìŠ¤íŠ¸ ë‚´ìš© (ê°€ëŠ¥í•œ ê²½ìš°)
4. ìƒ‰ìƒê³¼ ë””ìì¸ íŠ¹ì§•
5. ì‚¬ìš©ìê°€ í•  ìˆ˜ ìˆëŠ” ì£¼ìš” ì•¡ì…˜ë“¤

í•œêµ­ì–´ë¡œ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
        else:
            prompt = custom_prompt
        
        return self._generate_response(image_input, prompt)
    
    def analyze_ui_elements(self, image_input):
        """
        UI ìš”ì†Œë“¤ì„ ë¶„ì„í•˜ê³  ëª©ë¡í™”
        
        Args:
            image_input: ì´ë¯¸ì§€ ê²½ë¡œ, URL, ë˜ëŠ” PIL Image
            
        Returns:
            str: UI ìš”ì†Œ ë¶„ì„ ê²°ê³¼
        """
        prompt = """ì´ í™”ë©´ì˜ ëª¨ë“  UI ìš”ì†Œë“¤ì„ ë¶„ì„í•˜ê³  ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‚˜ì—´í•´ì£¼ì„¸ìš”:

[UI ìš”ì†Œ ë¶„ì„]
1. ë²„íŠ¼: (ë²„íŠ¼ ì´ë¦„ê³¼ ìœ„ì¹˜)
2. í…ìŠ¤íŠ¸ ì…ë ¥ì°½: (ì…ë ¥ì°½ ì´ë¦„ê³¼ ìœ„ì¹˜)
3. í…ìŠ¤íŠ¸/ë¼ë²¨: (í‘œì‹œëœ í…ìŠ¤íŠ¸ ë‚´ìš©)
4. ë©”ë‰´/ë„¤ë¹„ê²Œì´ì…˜: (ë©”ë‰´ í•­ëª©ë“¤)
5. ì´ë¯¸ì§€/ì•„ì´ì½˜: (ì•„ì´ì½˜ ì„¤ëª…)
6. ê¸°íƒ€ ìš”ì†Œ: (ê¸°íƒ€ ì¤‘ìš”í•œ UI ìš”ì†Œë“¤)

ê° ìš”ì†Œì˜ ëŒ€ëµì ì¸ ìœ„ì¹˜(ìƒë‹¨/ì¤‘ì•™/í•˜ë‹¨, ì¢Œì¸¡/ì¤‘ì•™/ìš°ì¸¡)ë„ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”.
í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
        
        return self._generate_response(image_input, prompt)
    
    def extract_text_content(self, image_input):
        """
        ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œí•˜ê³  ì •ë¦¬
        
        Args:
            image_input: ì´ë¯¸ì§€ ê²½ë¡œ, URL, ë˜ëŠ” PIL Image
            
        Returns:
            str: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë‚´ìš©
        """
        prompt = """ì´ ì´ë¯¸ì§€ì— í‘œì‹œëœ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ì •ë¦¬í•´ì£¼ì„¸ìš”:

[í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼]
1. ì œëª©/í—¤ë”: 
2. ë³¸ë¬¸ í…ìŠ¤íŠ¸:
3. ë²„íŠ¼ í…ìŠ¤íŠ¸:
4. ë©”ë‰´ í•­ëª©:
5. ì…ë ¥ íŒíŠ¸/í”Œë ˆì´ìŠ¤í™€ë”:
6. ê¸°íƒ€ í…ìŠ¤íŠ¸:

í…ìŠ¤íŠ¸ì˜ ìœ„ì¹˜ì™€ ì¤‘ìš”ë„ë„ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”.
í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
        
        return self._generate_response(image_input, prompt)
    
    def suggest_actions(self, image_input):
        """
        í™”ë©´ì—ì„œ ì‚¬ìš©ìê°€ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì•¡ì…˜ë“¤ì„ ì œì•ˆ
        
        Args:
            image_input: ì´ë¯¸ì§€ ê²½ë¡œ, URL, ë˜ëŠ” PIL Image
            
        Returns:
            str: ê°€ëŠ¥í•œ ì•¡ì…˜ë“¤ ëª©ë¡
        """
        prompt = """ì´ í™”ë©´ì„ ë³´ê³  ì‚¬ìš©ìê°€ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì£¼ìš” ì•¡ì…˜ë“¤ì„ ì œì•ˆí•´ì£¼ì„¸ìš”:

[ê°€ëŠ¥í•œ ì•¡ì…˜ë“¤]
1. í´ë¦­ ê°€ëŠ¥í•œ ìš”ì†Œë“¤:
2. ì…ë ¥ ê°€ëŠ¥í•œ í•„ë“œë“¤:
3. ìŠ¤í¬ë¡¤/ë„¤ë¹„ê²Œì´ì…˜:
4. ë©”ë‰´/ì„¤ì • ì ‘ê·¼:
5. ì£¼ìš” ê¸°ëŠ¥ ì‚¬ìš©ë²•:

ê° ì•¡ì…˜ì— ëŒ€í•´ ì–´ë–¤ ê²°ê³¼ê°€ ì˜ˆìƒë˜ëŠ”ì§€ë„ ì„¤ëª…í•´ì£¼ì„¸ìš”.
í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
        
        return self._generate_response(image_input, prompt)
    
    def identify_app_type(self, image_input):
        """
        ì•±ì´ë‚˜ ì›¹ì‚¬ì´íŠ¸ì˜ ì¢…ë¥˜ë¥¼ ì‹ë³„
        
        Args:
            image_input: ì´ë¯¸ì§€ ê²½ë¡œ, URL, ë˜ëŠ” PIL Image
            
        Returns:
            str: ì•± ì¢…ë¥˜ ì‹ë³„ ê²°ê³¼
        """
        prompt = """ì´ í™”ë©´ì„ ë³´ê³  ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

[ì•±/ì›¹ì‚¬ì´íŠ¸ ë¶„ì„]
1. ì•± ì¢…ë¥˜: (ì†Œì…œë¯¸ë””ì–´, ì‡¼í•‘, ë‰´ìŠ¤, ê²Œì„, ìƒì‚°ì„± ë„êµ¬ ë“±)
2. ì£¼ìš” ê¸°ëŠ¥: (ì´ ì•±ì˜ í•µì‹¬ ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€)
3. íƒ€ê²Ÿ ì‚¬ìš©ì: (ì–´ë–¤ ì‚¬ìš©ìë¥¼ ìœ„í•œ ì•±ì¸ê°€)
4. ë””ìì¸ íŠ¹ì§•: (UI/UX íŠ¹ì§•)
5. ê²½ìŸ ì•±: (ë¹„ìŠ·í•œ ê¸°ëŠ¥ì˜ ì•±ë“¤)

í•œêµ­ì–´ë¡œ ìƒì„¸í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”."""
        
        return self._generate_response(image_input, prompt)
    
    def _generate_response(self, image_input, prompt):
        """
        Qwen2VL ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„± (ë‚´ë¶€ ë©”ì„œë“œ)
        
        Args:
            image_input: ì´ë¯¸ì§€ ì…ë ¥
            prompt: ì§ˆë¬¸/í”„ë¡¬í”„íŠ¸
            
        Returns:
            str: ëª¨ë¸ì˜ ì‘ë‹µ
        """
        try:
            start_time = time.time()
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = self.load_image(image_input)
            
            # ë©”ì‹œì§€ êµ¬ì„± (Qwen2VL í˜•ì‹)
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image",
                            "image": image_input if isinstance(image_input, str) else image,
                            "min_pixels": self.min_pixels,
                            "max_pixels": self.max_pixels,
                        },
                    ],
                }
            ]
            
            # í…œí”Œë¦¿ ì ìš©
            text = self.processor.apply_chat_template(
                messages, tokenize=False, add_generation_prompt=True
            )
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            image_inputs, video_inputs = process_vision_info(messages)
            
            # ì…ë ¥ í† í°í™”
            inputs = self.processor(
                text=[text],
                images=image_inputs,
                videos=video_inputs,
                padding=True,
                return_tensors="pt",
            )
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            inputs = inputs.to(self.device)
            
            # ì‘ë‹µ ìƒì„±
            print("ğŸ”„ ì‘ë‹µ ìƒì„± ì¤‘...")
            generated_ids = self.model.generate(
                **inputs, 
                max_new_tokens=1024,
                do_sample=True,
                temperature=0.7,
                top_p=0.9
            )
            
            # ê²°ê³¼ ë””ì½”ë”©
            generated_ids_trimmed = [
                out_ids[len(in_ids):] 
                for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            
            output_text = self.processor.batch_decode(
                generated_ids_trimmed, 
                skip_special_tokens=True, 
                clean_up_tokenization_spaces=False
            )[0]
            
            end_time = time.time()
            print(f"â±ï¸ ì‘ë‹µ ìƒì„± ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
            
            return output_text.strip()
            
        except Exception as e:
            return f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì„¤ëª… ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸
    """
    print("ğŸš€ Qwen2VL ì´ë¯¸ì§€ ì„¤ëª… í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # Qwen2VL ì„¤ëª…ê¸° ì´ˆê¸°í™”
    try:
        describer = Qwen2VLDescriber()
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ í•´ê²° ë°©ë²•:")
        print("1. ì¸í„°ë„· ì—°ê²° í™•ì¸")
        print("2. torch ë° transformers íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸")
        print("3. GPU ë©”ëª¨ë¦¬ í™•ì¸ (CPU ëª¨ë“œ ì‹œë„: device='cpu')")
        return
    
    # í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ íŒŒì¼ë“¤
    test_images = [
        "test_screenshot.png",  # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
        # ì¶”ê°€ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë“¤ì„ ì—¬ê¸°ì— ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
    ]
    
    for image_path in test_images:
        if not os.path.exists(image_path):
            print(f"âš ï¸  ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            print(f"ğŸ’¡ í˜„ì¬ ë””ë ‰í† ë¦¬ì— '{image_path}' íŒŒì¼ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            continue
            
        print(f"\nğŸ“¸ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘: {image_path}")
        print("-" * 40)
        
        # 1. ì „ì²´ ì´ë¯¸ì§€ ì„¤ëª…
        print("\n1ï¸âƒ£ ì „ì²´ ì´ë¯¸ì§€ ì„¤ëª…:")
        description = describer.describe_image(image_path)
        print(description)
        
        # 2. UI ìš”ì†Œ ë¶„ì„
        print("\n2ï¸âƒ£ UI ìš”ì†Œ ë¶„ì„:")
        ui_analysis = describer.analyze_ui_elements(image_path)
        print(ui_analysis)
        
        # 3. í…ìŠ¤íŠ¸ ì¶”ì¶œ
        print("\n3ï¸âƒ£ í…ìŠ¤íŠ¸ ì¶”ì¶œ:")
        text_content = describer.extract_text_content(image_path)
        print(text_content)
        
        # 4. ì•¡ì…˜ ì œì•ˆ
        print("\n4ï¸âƒ£ ê°€ëŠ¥í•œ ì•¡ì…˜ë“¤:")
        actions = describer.suggest_actions(image_path)
        print(actions)
        
        # 5. ì•± ì¢…ë¥˜ ì‹ë³„
        print("\n5ï¸âƒ£ ì•± ì¢…ë¥˜ ì‹ë³„:")
        app_type = describer.identify_app_type(image_path)
        print(app_type)
        
        print("\n" + "="*60)
    
    print("âœ… ì´ë¯¸ì§€ ì„¤ëª… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

def interactive_mode():
    """
    ëŒ€í™”í˜• ëª¨ë“œ - ì‚¬ìš©ìê°€ ì§ì ‘ ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ì„ ì…ë ¥
    """
    print("ğŸ”„ ëŒ€í™”í˜• ëª¨ë“œ ì‹œì‘")
    print("ì´ë¯¸ì§€ ê²½ë¡œì™€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. 'quit'ë¥¼ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")
    
    try:
        describer = Qwen2VLDescriber()
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    while True:
        print("\n" + "-"*40)
        image_path = input("ğŸ“ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        
        if image_path.lower() == 'quit':
            break
            
        if not os.path.exists(image_path):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            continue
        
        question = input("â“ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì—”í„°ë§Œ ëˆ„ë¥´ë©´ ê¸°ë³¸ ì„¤ëª…): ").strip()
        
        print("\nğŸ¤– ë¶„ì„ ì¤‘...")
        if question:
            result = describer.describe_image(image_path, question)
        else:
            result = describer.describe_image(image_path)
        
        print(f"\nğŸ“ ê²°ê³¼:\n{result}")
    
    print("ğŸ‘‹ ëŒ€í™”í˜• ëª¨ë“œ ì¢…ë£Œ")

if __name__ == "__main__":
    # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    main()
    
    # ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰ ì—¬ë¶€ ì„ íƒ
    choice = input("\nğŸ¯ ëŒ€í™”í˜• ëª¨ë“œë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
    if choice == 'y':
        interactive_mode() 