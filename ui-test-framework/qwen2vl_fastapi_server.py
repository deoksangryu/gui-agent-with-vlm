"""
Qwen2VL FastAPI ì„œë²„

í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° base64 ì´ë¯¸ì§€ë¥¼ ë°›ì•„ì„œ í´ë¦­ ê°€ëŠ¥í•œ ìš”ì†Œë“¤ì„ 
ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ë¡œ ë°˜í™˜í•˜ëŠ” FastAPI ì„œë²„ì…ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    uvicorn qwen2vl_fastapi_server:app --host 0.0.0.0 --port 8000
"""

import base64
import io
import torch
import time
from typing import Optional
from PIL import Image
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from qwen_vl_utils import process_vision_info
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor

# GPU ìµœì í™” ì„¤ì •
torch.backends.cuda.enable_mem_efficient_sdp(False)
torch.backends.cuda.enable_flash_sdp(False)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Qwen2VL í´ë¦­ ìš”ì†Œ ë¶„ì„ API",
    description="í´ë¦­í•  ìš”ì†Œë“¤ì„ ,ë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ë¡œ ì •ë¦¬",
    version="1.0.0"
)

# CORS ì„¤ì • (í•„ìš”ì— ë”°ë¼ ì¡°ì •)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì‹¤ì œ ìš´ì˜í™˜ê²½ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ë§Œ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ìš”ì²­/ì‘ë‹µ ëª¨ë¸
class ImageAnalysisRequest(BaseModel):
    """ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­ ëª¨ë¸"""
    image_base64: str
    context: Optional[str] = ""  # ì„ íƒì  ì»¨í…ìŠ¤íŠ¸ ì •ë³´

class ImageAnalysisResponse(BaseModel):
    """ì´ë¯¸ì§€ ë¶„ì„ ì‘ë‹µ ëª¨ë¸"""
    clickable_elements: str
    processing_time: float
    success: bool
    error_message: Optional[str] = None

# ì „ì—­ ëª¨ë¸ ë³€ìˆ˜
model = None
processor = None
device = None

class Qwen2VLAnalyzer:
    """Qwen2VL ë¶„ì„ê¸° í´ë˜ìŠ¤"""
    
    def __init__(self, model_name="Qwen/Qwen2-VL-2B-Instruct", device="auto"):
        """ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        print("ğŸ¯ Qwen2VL ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬ ì„¤ì •
        self.min_pixels = 256 * 28 * 28
        self.max_pixels = 1344 * 28 * 28
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if device == "auto":
            if torch.cuda.is_available():
                self.device = "cuda"
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                self.device = "mps"
            else:
                self.device = "cpu"
        else:
            self.device = device
        
        print(f"ğŸ“± ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")
        
        # í”„ë¡œì„¸ì„œ ë° ëª¨ë¸ ë¡œë“œ
        self.processor = AutoProcessor.from_pretrained(
            model_name,
            min_pixels=self.min_pixels,
            max_pixels=self.max_pixels
        )
        
        if self.device == "cpu":
            self.model = Qwen2VLForConditionalGeneration.from_pretrained(
                model_name,
                torch_dtype=torch.float32,
                device_map="cpu"
            )
        else:
            self.model = Qwen2VLForConditionalGeneration.from_pretrained(
                model_name,
                torch_dtype=torch.bfloat16,
                device_map=self.device
            )
        
        print("âœ… Qwen2VL ë¶„ì„ê¸° ì¤€ë¹„ ì™„ë£Œ!")
    
    def analyze_clickable_elements(self, image: Image.Image, context: str = "") -> str:
        """
        ì´ë¯¸ì§€ì—ì„œ í´ë¦­ ê°€ëŠ¥í•œ ìš”ì†Œë“¤ì„ ë¶„ì„í•˜ì—¬ ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ë¡œ ë°˜í™˜
        
        Args:
            image: PIL Image ê°ì²´
            context: ì„ íƒì  ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            
        Returns:
            str: í´ë¦­ ê°€ëŠ¥í•œ ìš”ì†Œë“¤ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•œ ë¬¸ìì—´
        """
        
        # ë” ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ í”„ë¡¬í”„íŠ¸
        prompt = f"""ì´ ìŠ¤í¬ë¦°ìƒ·ì—ì„œ ì‹¤ì œë¡œ í´ë¦­í•  ìˆ˜ ìˆëŠ” UI ìš”ì†Œë“¤ë§Œ ì°¾ì•„ì„œ ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë‹µí•´ì£¼ì„¸ìš”.

í´ë¦­ ê°€ëŠ¥í•œ ìš”ì†Œë€:
- ë²„íŠ¼ (ë¡œê·¸ì¸, ê²€ìƒ‰, ë©”ë‰´ ë“±)
- ë§í¬ (í…ìŠ¤íŠ¸ ë§í¬, ì¢…ëª©ëª… ë§í¬ ë“±)
- ì•„ì´ì½˜ (ë„¤ë¹„ê²Œì´ì…˜, ì„¤ì • ë“±)
- íƒ­ ë©”ë‰´
- ë“œë¡­ë‹¤ìš´ ë©”ë‰´

í´ë¦­í•  ìˆ˜ ì—†ëŠ” ë‹¨ìˆœ í…ìŠ¤íŠ¸ë‚˜ ìˆ«ìëŠ” ì œì™¸í•˜ê³ , ì˜¤ì§ ìƒí˜¸ì‘ìš© ê°€ëŠ¥í•œ ìš”ì†Œë“¤ë§Œ ë‚˜ì—´í•´ì£¼ì„¸ìš”.

ì¶œë ¥ í˜•ì‹: ìš”ì†Œ1, ìš”ì†Œ2, ìš”ì†Œ3, ...

{f"í™”ë©´ ì •ë³´: {context}" if context.strip() else ""}"""
        
        try:
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image",
                            "image": image,
                            "min_pixels": self.min_pixels,
                            "max_pixels": self.max_pixels,
                        },
                    ],
                }
            ]
            
            # í…œí”Œë¦¿ ì ìš© ë° ì²˜ë¦¬
            text = self.processor.apply_chat_template(
                messages, tokenize=False, add_generation_prompt=True
            )
            
            image_inputs, video_inputs = process_vision_info(messages)
            
            inputs = self.processor(
                text=[text],
                images=image_inputs,
                videos=video_inputs,
                padding=True,
                return_tensors="pt",
            )
            
            inputs = inputs.to(self.device)
            
            # ì‘ë‹µ ìƒì„± (ë” ìì„¸í•œ ì‘ë‹µì„ ìœ„í•œ ì„¤ì •)
            generated_ids = self.model.generate(
                **inputs, 
                max_new_tokens=2000,  # ë” ê¸´ ì‘ë‹µì„ ìœ„í•´ ì¦ê°€
                do_sample=True,  # ìƒ˜í”Œë§ í™œì„±í™”
                temperature=0.3,  # ì ë‹¹í•œ ì°½ì˜ì„±
                top_p=0.9,
                repetition_penalty=1.1,  # ë°˜ë³µ ë°©ì§€ (ë„ˆë¬´ ë†’ì§€ ì•Šê²Œ)
                pad_token_id=self.processor.tokenizer.eos_token_id,
                eos_token_id=self.processor.tokenizer.eos_token_id
            )
            
            # ê²°ê³¼ ë””ì½”ë”©
            generated_ids_trimmed = [
                out_ids[len(in_ids):] 
                for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            
            output_text = self.processor.batch_decode(
                generated_ids_trimmed, 
                skip_special_tokens=True, 
                clean_up_tokenization_spaces=False
            )[0]
            
            # ê²°ê³¼ ì •ë¦¬ (ë” ê´€ëŒ€í•œ ê¸¸ì´ ì œí•œ)
            result = output_text.strip()
            # ì—¬ëŸ¬ ì¤„ì¸ ê²½ìš° ì²« ë²ˆì§¸ ë¬¸ë‹¨ê¹Œì§€ë§Œ ì‚¬ìš©
            if '\n\n' in result:
                result = result.split('\n\n')[0]
            if len(result) > 1500:  # ë” ê¸´ ì‘ë‹µ í—ˆìš©
                result = result[:1500] + "..."
            
            return result
            
        except Exception as e:
            raise Exception(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# ì „ì—­ ë¶„ì„ê¸° ì´ˆê¸°í™”
analyzer = None

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë“œ"""
    global analyzer
    try:
        print("ğŸš€ FastAPI ì„œë²„ ì‹œì‘ - ëª¨ë¸ ë¡œë”© ì¤‘...")
        analyzer = Qwen2VLAnalyzer()
        print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        raise

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "Qwen2VL í´ë¦­ ìš”ì†Œ ë¶„ì„ API",
        "version": "1.0.0",
        "endpoints": {
            "POST /analyze": "ì´ë¯¸ì§€ ë¶„ì„",
            "GET /health": "ì„œë²„ ìƒíƒœ í™•ì¸"
        }
    }

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    global analyzer
    return {
        "status": "healthy" if analyzer is not None else "not_ready",
        "model_loaded": analyzer is not None,
        "device": analyzer.device if analyzer else "unknown"
    }

@app.post("/analyze", response_model=ImageAnalysisResponse)
async def analyze_image(request: ImageAnalysisRequest):
    """
    ì´ë¯¸ì§€ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸
    
    Args:
        request: base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ì™€ ì„ íƒì  ì»¨í…ìŠ¤íŠ¸
        
    Returns:
        ImageAnalysisResponse: í´ë¦­ ê°€ëŠ¥í•œ ìš”ì†Œë“¤ì˜ ì‰¼í‘œ êµ¬ë¶„ ë¬¸ìì—´
    """
    global analyzer
    
    if analyzer is None:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ì•„ì§ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    start_time = time.time()
    
    try:
        # Base64 ì´ë¯¸ì§€ ë””ì½”ë”©
        try:
            # base64 í—¤ë” ì œê±° (data:image/png;base64, ë“±)
            if ',' in request.image_base64:
                base64_data = request.image_base64.split(',')[1]
            else:
                base64_data = request.image_base64
            
            # Base64 ë””ì½”ë”©
            image_data = base64.b64decode(base64_data)
            image = Image.open(io.BytesIO(image_data))
            
            # RGBAë¥¼ RGBë¡œ ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)
            if image.mode == 'RGBA':
                image = image.convert('RGB')
                
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: {str(e)}")
        
        # ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰
        try:
            clickable_elements = analyzer.analyze_clickable_elements(image, request.context)
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        
        processing_time = time.time() - start_time
        
        return ImageAnalysisResponse(
            clickable_elements=clickable_elements,
            processing_time=processing_time,
            success=True
        )
        
    except HTTPException:
        raise
    except Exception as e:
        processing_time = time.time() - start_time
        return ImageAnalysisResponse(
            clickable_elements="",
            processing_time=processing_time,
            success=False,
            error_message=str(e)
        )

if __name__ == "__main__":
    import uvicorn
    
    print("ğŸŒ Qwen2VL FastAPI ì„œë²„ ì‹œì‘")
    print("ğŸ“ ì„œë²„ ì£¼ì†Œ: http://localhost:8000")
    print("ğŸ“– API ë¬¸ì„œ: http://localhost:8000/docs")
    
    uvicorn.run(
        "qwen2vl_fastapi_server:app",
        host="0.0.0.0",
        port=8000,
        reload=False,  # í”„ë¡œë•ì…˜ì—ì„œëŠ” False
        log_level="info"
    ) 