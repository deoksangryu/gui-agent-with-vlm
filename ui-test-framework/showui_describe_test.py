"""
ShowUI ì´ë¯¸ì§€ ì„¤ëª… í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ShowUI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ì„¤ëª…í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
ê¸°ì¡´ì˜ í´ë¦­ ì¢Œí‘œ ê°ì§€ ê¸°ëŠ¥ê³¼ í•¨ê»˜ ì´ë¯¸ì§€ ì „ì²´ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ë„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. ì´ë¯¸ì§€ ì „ì²´ ì„¤ëª… ìƒì„±
2. UI ìš”ì†Œ ì‹ë³„ ë° ì„¤ëª…
3. í…ìŠ¤íŠ¸ ì¸ì‹ ë° ìš”ì•½
4. í™”ë©´ ë ˆì´ì•„ì›ƒ ë¶„ì„
"""

import os
import torch
from PIL import Image
from io import BytesIO
import requests
from qwen_vl_utils import process_vision_info
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor

class ShowUIDescriber:
    """
    ShowUIë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì„¤ëª… í´ë˜ìŠ¤
    """
    
    def __init__(self, model_name="showlab/ShowUI-2B", device="cpu"):
        """
        ShowUI ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            model_name: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (cpu, cuda, mps ë“±)
        """
        print(f"ShowUI ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = Qwen2VLForConditionalGeneration.from_pretrained(
            model_name,
            torch_dtype=torch.bfloat16,
            device_map=device
        )
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬ ì„¤ì •
        self.min_pixels = 256 * 28 * 28
        self.max_pixels = 1344 * 28 * 28
        self.size = {"shortest_edge": self.min_pixels, "longest_edge": self.max_pixels}
        
        # í”„ë¡œì„¸ì„œ ë¡œë“œ
        self.processor = AutoProcessor.from_pretrained(
            model_name, 
            min_pixels=self.min_pixels, 
            max_pixels=self.max_pixels, 
            size=self.size
        )
        
        self.device = device
        print(f"ShowUI ëª¨ë¸ ë¡œë”© ì™„ë£Œ (ë””ë°”ì´ìŠ¤: {device})")
    
    def load_image(self, image_input):
        """
        ì´ë¯¸ì§€ ë¡œë“œ (íŒŒì¼ ê²½ë¡œ, URL, PIL Image ì§€ì›)
        
        Args:
            image_input: ì´ë¯¸ì§€ ê²½ë¡œ, URL, ë˜ëŠ” PIL Image ê°ì²´
            
        Returns:
            PIL.Image: ë¡œë“œëœ ì´ë¯¸ì§€
        """
        if isinstance(image_input, str):
            if image_input.startswith('http'):
                # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                response = requests.get(image_input)
                image = Image.open(BytesIO(response.content))
            else:
                # ë¡œì»¬ íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
                image = Image.open(image_input)
        else:
            # ì´ë¯¸ PIL Imageì¸ ê²½ìš°
            image = image_input
        
        return image
    
    def describe_image(self, image_input, custom_prompt=None):
        """
        ì´ë¯¸ì§€ ì „ì²´ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª… ìƒì„±
        
        Args:
            image_input: ì´ë¯¸ì§€ ê²½ë¡œ, URL, ë˜ëŠ” PIL Image
            custom_prompt: ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ (ì„ íƒì‚¬í•­)
            
        Returns:
            str: ì´ë¯¸ì§€ ì„¤ëª… í…ìŠ¤íŠ¸
        """
        # ê¸°ë³¸ ì„¤ëª… í”„ë¡¬í”„íŠ¸
        if custom_prompt is None:
            prompt = """ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. ë‹¤ìŒ ì‚¬í•­ë“¤ì„ í¬í•¨í•´ì£¼ì„¸ìš”:
1. ì „ë°˜ì ì¸ í™”ë©´ êµ¬ì„±ê³¼ ë ˆì´ì•„ì›ƒ
2. ì£¼ìš” UI ìš”ì†Œë“¤ (ë²„íŠ¼, í…ìŠ¤íŠ¸, ì…ë ¥ì°½ ë“±)
3. í…ìŠ¤íŠ¸ ë‚´ìš© (ê°€ëŠ¥í•œ ê²½ìš°)
4. ìƒ‰ìƒê³¼ ë””ìì¸ íŠ¹ì§•
5. ì‚¬ìš©ìê°€ í•  ìˆ˜ ìˆëŠ” ì£¼ìš” ì•¡ì…˜ë“¤"""
        else:
            prompt = custom_prompt
        
        return self._generate_response(image_input, prompt)
    
    def analyze_ui_elements(self, image_input):
        """
        UI ìš”ì†Œë“¤ì„ ë¶„ì„í•˜ê³  ëª©ë¡í™”
        
        Args:
            image_input: ì´ë¯¸ì§€ ê²½ë¡œ, URL, ë˜ëŠ” PIL Image
            
        Returns:
            str: UI ìš”ì†Œ ë¶„ì„ ê²°ê³¼
        """
        prompt = """ì´ í™”ë©´ì˜ ëª¨ë“  UI ìš”ì†Œë“¤ì„ ë¶„ì„í•˜ê³  ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‚˜ì—´í•´ì£¼ì„¸ìš”:

[UI ìš”ì†Œ ë¶„ì„]
1. ë²„íŠ¼: (ë²„íŠ¼ ì´ë¦„ê³¼ ìœ„ì¹˜)
2. í…ìŠ¤íŠ¸ ì…ë ¥ì°½: (ì…ë ¥ì°½ ì´ë¦„ê³¼ ìœ„ì¹˜)
3. í…ìŠ¤íŠ¸/ë¼ë²¨: (í‘œì‹œëœ í…ìŠ¤íŠ¸ ë‚´ìš©)
4. ë©”ë‰´/ë„¤ë¹„ê²Œì´ì…˜: (ë©”ë‰´ í•­ëª©ë“¤)
5. ì´ë¯¸ì§€/ì•„ì´ì½˜: (ì•„ì´ì½˜ ì„¤ëª…)
6. ê¸°íƒ€ ìš”ì†Œ: (ê¸°íƒ€ ì¤‘ìš”í•œ UI ìš”ì†Œë“¤)

ê° ìš”ì†Œì˜ ëŒ€ëµì ì¸ ìœ„ì¹˜(ìƒë‹¨/ì¤‘ì•™/í•˜ë‹¨, ì¢Œì¸¡/ì¤‘ì•™/ìš°ì¸¡)ë„ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
        
        return self._generate_response(image_input, prompt)
    
    def extract_text_content(self, image_input):
        """
        ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œí•˜ê³  ì •ë¦¬
        
        Args:
            image_input: ì´ë¯¸ì§€ ê²½ë¡œ, URL, ë˜ëŠ” PIL Image
            
        Returns:
            str: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë‚´ìš©
        """
        prompt = """ì´ ì´ë¯¸ì§€ì— í‘œì‹œëœ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ì •ë¦¬í•´ì£¼ì„¸ìš”:

[í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼]
1. ì œëª©/í—¤ë”: 
2. ë³¸ë¬¸ í…ìŠ¤íŠ¸:
3. ë²„íŠ¼ í…ìŠ¤íŠ¸:
4. ë©”ë‰´ í•­ëª©:
5. ì…ë ¥ íŒíŠ¸/í”Œë ˆì´ìŠ¤í™€ë”:
6. ê¸°íƒ€ í…ìŠ¤íŠ¸:

í…ìŠ¤íŠ¸ì˜ ìœ„ì¹˜ì™€ ì¤‘ìš”ë„ë„ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
        
        return self._generate_response(image_input, prompt)
    
    def suggest_actions(self, image_input):
        """
        í™”ë©´ì—ì„œ ì‚¬ìš©ìê°€ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì•¡ì…˜ë“¤ì„ ì œì•ˆ
        
        Args:
            image_input: ì´ë¯¸ì§€ ê²½ë¡œ, URL, ë˜ëŠ” PIL Image
            
        Returns:
            str: ê°€ëŠ¥í•œ ì•¡ì…˜ë“¤ ëª©ë¡
        """
        prompt = """ì´ í™”ë©´ì„ ë³´ê³  ì‚¬ìš©ìê°€ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì£¼ìš” ì•¡ì…˜ë“¤ì„ ì œì•ˆí•´ì£¼ì„¸ìš”:

[ê°€ëŠ¥í•œ ì•¡ì…˜ë“¤]
1. í´ë¦­ ê°€ëŠ¥í•œ ìš”ì†Œë“¤:
2. ì…ë ¥ ê°€ëŠ¥í•œ í•„ë“œë“¤:
3. ìŠ¤í¬ë¡¤/ë„¤ë¹„ê²Œì´ì…˜:
4. ë©”ë‰´/ì„¤ì • ì ‘ê·¼:
5. ì£¼ìš” ê¸°ëŠ¥ ì‚¬ìš©ë²•:

ê° ì•¡ì…˜ì— ëŒ€í•´ ì–´ë–¤ ê²°ê³¼ê°€ ì˜ˆìƒë˜ëŠ”ì§€ë„ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
        
        return self._generate_response(image_input, prompt)
    
    def _generate_response(self, image_input, prompt):
        """
        ShowUI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„± (ë‚´ë¶€ ë©”ì„œë“œ)
        
        Args:
            image_input: ì´ë¯¸ì§€ ì…ë ¥
            prompt: ì§ˆë¬¸/í”„ë¡¬í”„íŠ¸
            
        Returns:
            str: ëª¨ë¸ì˜ ì‘ë‹µ
        """
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = self.load_image(image_input)
            
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image", 
                            "image": image_input if isinstance(image_input, str) else image,
                            "min_pixels": self.min_pixels, 
                            "max_pixels": self.max_pixels
                        }
                    ],
                }
            ]
            
            # í…œí”Œë¦¿ ì ìš©
            text = self.processor.apply_chat_template(
                messages, tokenize=False, add_generation_prompt=True
            )
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            image_inputs, video_inputs = process_vision_info(messages)
            
            # ì…ë ¥ í† í°í™”
            inputs = self.processor(
                text=[text],
                images=image_inputs,
                videos=video_inputs,
                padding=True,
                return_tensors="pt",
            )
            inputs = inputs.to(self.device)
            
            # ì‘ë‹µ ìƒì„±
            generated_ids = self.model.generate(**inputs, max_new_tokens=512)
            generated_ids_trimmed = [
                out_ids[len(in_ids):] 
                for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            
            # í…ìŠ¤íŠ¸ ë””ì½”ë”©
            output_text = self.processor.batch_decode(
                generated_ids_trimmed, 
                skip_special_tokens=True, 
                clean_up_tokenization_spaces=False
            )[0]
            
            return output_text.strip()
            
        except Exception as e:
            return f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì„¤ëª… ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸
    """
    print("ğŸ¤– ShowUI ì´ë¯¸ì§€ ì„¤ëª… í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # ShowUI ì„¤ëª…ê¸° ì´ˆê¸°í™”
    describer = ShowUIDescriber()
    
    # í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ íŒŒì¼ (ì˜ˆì œ)
    test_images = [
        "test_screenshot.png",  # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
        # ì¶”ê°€ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë“¤ì„ ì—¬ê¸°ì— ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
    ]
    
    for image_path in test_images:
        if not os.path.exists(image_path):
            print(f"âš ï¸  ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            continue
            
        print(f"\nğŸ“¸ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘: {image_path}")
        print("-" * 40)
        
        # 1. ì „ì²´ ì´ë¯¸ì§€ ì„¤ëª…
        print("\n1ï¸âƒ£ ì „ì²´ ì´ë¯¸ì§€ ì„¤ëª…:")
        description = describer.describe_image(image_path)
        print(description)
        
        # 2. UI ìš”ì†Œ ë¶„ì„
        print("\n2ï¸âƒ£ UI ìš”ì†Œ ë¶„ì„:")
        ui_analysis = describer.analyze_ui_elements(image_path)
        print(ui_analysis)
        
        # 3. í…ìŠ¤íŠ¸ ì¶”ì¶œ
        print("\n3ï¸âƒ£ í…ìŠ¤íŠ¸ ì¶”ì¶œ:")
        text_content = describer.extract_text_content(image_path)
        print(text_content)
        
        # 4. ì•¡ì…˜ ì œì•ˆ
        print("\n4ï¸âƒ£ ê°€ëŠ¥í•œ ì•¡ì…˜ë“¤:")
        actions = describer.suggest_actions(image_path)
        print(actions)
        
        print("\n" + "="*60)
    
    print("âœ… ì´ë¯¸ì§€ ì„¤ëª… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

def interactive_mode():
    """
    ëŒ€í™”í˜• ëª¨ë“œ - ì‚¬ìš©ìê°€ ì§ì ‘ ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ì„ ì…ë ¥
    """
    print("ğŸ”„ ëŒ€í™”í˜• ëª¨ë“œ ì‹œì‘")
    print("ì´ë¯¸ì§€ ê²½ë¡œì™€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. 'quit'ë¥¼ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")
    
    describer = ShowUIDescriber()
    
    while True:
        print("\n" + "-"*40)
        image_path = input("ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        
        if image_path.lower() == 'quit':
            break
            
        if not os.path.exists(image_path):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            continue
        
        question = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì—”í„°ë§Œ ëˆ„ë¥´ë©´ ê¸°ë³¸ ì„¤ëª…): ").strip()
        
        print("\nğŸ¤– ë¶„ì„ ì¤‘...")
        if question:
            result = describer.describe_image(image_path, question)
        else:
            result = describer.describe_image(image_path)
        
        print(f"\nğŸ“ ê²°ê³¼:\n{result}")
    
    print("ğŸ‘‹ ëŒ€í™”í˜• ëª¨ë“œ ì¢…ë£Œ")

if __name__ == "__main__":
    # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    main()
    
    # ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰ ì—¬ë¶€ ì„ íƒ
    choice = input("\nëŒ€í™”í˜• ëª¨ë“œë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
    if choice == 'y':
        interactive_mode() 